{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>45</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>92</td>\n",
       "      <td>3.330</td>\n",
       "      <td>0.755688</td>\n",
       "      <td>54.6800</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.96000</td>\n",
       "      <td>268.230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>62</td>\n",
       "      <td>26.840000</td>\n",
       "      <td>100</td>\n",
       "      <td>4.530</td>\n",
       "      <td>1.117400</td>\n",
       "      <td>12.4500</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>7.32000</td>\n",
       "      <td>330.160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>65</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>97</td>\n",
       "      <td>5.730</td>\n",
       "      <td>1.370998</td>\n",
       "      <td>61.4800</td>\n",
       "      <td>22.540000</td>\n",
       "      <td>10.33000</td>\n",
       "      <td>314.050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>72</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>82</td>\n",
       "      <td>2.820</td>\n",
       "      <td>0.570392</td>\n",
       "      <td>24.9600</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>3.27000</td>\n",
       "      <td>392.460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>86</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>138</td>\n",
       "      <td>19.910</td>\n",
       "      <td>6.777364</td>\n",
       "      <td>90.2800</td>\n",
       "      <td>14.110000</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>90.090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  \\\n",
       "0     48  23.500000       70    2.707  0.467409   8.8071     9.702400   \n",
       "1     83  20.690495       92    3.115  0.706897   8.8438     5.429285   \n",
       "2     82  23.124670       91    4.498  1.009651  17.9393    22.432040   \n",
       "3     68  21.367521       77    3.226  0.612725   9.8827     7.169560   \n",
       "4     86  21.111111       92    3.549  0.805386   6.6994     4.819240   \n",
       "..   ...        ...      ...      ...       ...      ...          ...   \n",
       "111   45  26.850000       92    3.330  0.755688  54.6800    12.100000   \n",
       "112   62  26.840000      100    4.530  1.117400  12.4500    21.420000   \n",
       "113   65  32.050000       97    5.730  1.370998  61.4800    22.540000   \n",
       "114   72  25.590000       82    2.820  0.570392  24.9600    33.750000   \n",
       "115   86  27.180000      138   19.910  6.777364  90.2800    14.110000   \n",
       "\n",
       "     Resistin    MCP.1  Classification  \n",
       "0     7.99585  417.114               1  \n",
       "1     4.06405  468.786               1  \n",
       "2     9.27715  554.697               1  \n",
       "3    12.76600  928.220               1  \n",
       "4    10.57635  773.920               1  \n",
       "..        ...      ...             ...  \n",
       "111  10.96000  268.230               2  \n",
       "112   7.32000  330.160               2  \n",
       "113  10.33000  314.050               2  \n",
       "114   3.27000  392.460               2  \n",
       "115   4.35000   90.090               2  \n",
       "\n",
       "[116 rows x 10 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataR2.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando Labels e Features e normalizando as features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização é necessária para melhor performance na utilização do KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = df.values[:, :-1]\n",
    "labels = df.values[:, -1]\n",
    "\n",
    "data = scaler.fit_transform(data_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN básico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o KNN básico, sem utilização de KFold para ter uma base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=70.83%\n",
      "k=3, accuracy=70.83%\n",
      "k=5, accuracy=87.50%\n",
      "k=7, accuracy=75.00%\n",
      "k=9, accuracy=75.00%\n",
      "k=11, accuracy=75.00%\n",
      "k=13, accuracy=70.83%\n",
      "k=15, accuracy=66.67%\n",
      "k=17, accuracy=66.67%\n",
      "k=19, accuracy=70.83%\n",
      "k=21, accuracy=66.67%\n",
      "k=23, accuracy=66.67%\n",
      "k=25, accuracy=66.67%\n",
      "k=27, accuracy=62.50%\n",
      "k=29, accuracy=58.33%\n",
      "accuracy=87.50%\n"
     ]
    }
   ],
   "source": [
    "trainData, testData, trainLabels, testLabels = train_test_split(data,\n",
    "labels, stratify=labels, test_size=0.2, random_state=42)\n",
    "\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "for k in kVals:\n",
    "        # train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "        model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "        model.fit(trainData, trainLabels)\n",
    "        # evaluate the model and update the accuracies list\n",
    "        score = model.score(testData, testLabels)\n",
    "        print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "        accuracies.append(score)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "model.fit(trainData, trainLabels)\n",
    "score = model.score(testData, testLabels)\n",
    "print(\"accuracy=%.2f%%\" % (score * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN com K Fold externo e interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5654970760233918, 0.564327485380117, 0.5742690058479532, 0.5654970760233918, 0.5754385964912281, 0.6187134502923977]\n",
      "\n",
      " Best K: 31, Accuracy: 70.83333333333334 \n",
      "\n",
      "[0.6111111111111112, 0.6421052631578947, 0.6309941520467837, 0.62046783625731, 0.6947368421052631, 0.643859649122807]\n",
      "\n",
      " Best K: 21, Accuracy: 56.52173913043478 \n",
      "\n",
      "[0.5923976608187135, 0.5912280701754385, 0.6011695906432748, 0.57953216374269, 0.5578947368421052, 0.6251461988304093]\n",
      "\n",
      " Best K: 31, Accuracy: 78.26086956521739 \n",
      "\n",
      "[0.5900584795321637, 0.6116959064327485, 0.5894736842105263, 0.5900584795321637, 0.5690058479532164, 0.504093567251462]\n",
      "\n",
      " Best K: 3, Accuracy: 65.21739130434783 \n",
      "\n",
      "[0.6883040935672514, 0.7, 0.6777777777777777, 0.6900584795321637, 0.7327485380116959, 0.6567251461988304]\n",
      "\n",
      " Best K: 21, Accuracy: 47.82608695652174 \n",
      "\n",
      "========================================\n",
      " Mean Accuracy \n",
      "========================================\n",
      "mean accuracy: 63.73%\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "kVals = [1, 3, 5, 11, 21, 31]\n",
    "\n",
    "# Etapa 1 - Separar em treino e teste\n",
    "accuracies = []\n",
    "for train, test in skf.split(data, labels):\n",
    "\n",
    "    # Etapa 2 - Para cada valor de hiperparametro\n",
    "    accuracies_kvals = []\n",
    "    for k in kVals:\n",
    "\n",
    "        # Etapa 2 - Para cada fold\n",
    "        models_accuracies = []\n",
    "        for t_train, t_test in skf.split(data[train], labels[train]):\n",
    "\n",
    "            # Etapa 2 - Treinar um modelo e medir a acurácia\n",
    "            model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "            model.fit(data[train[t_train]], labels[train[t_train]])\n",
    "            score = model.score(data[train[t_test]], labels[train[t_test]])\n",
    "            models_accuracies.append(score)\n",
    "        \n",
    "        # Etapa 2 - Salvar a acurácia média dos k folds para cada hiperparametro\n",
    "        kVal_mean_accuracy = mean(models_accuracies)\n",
    "        accuracies_kvals.append(kVal_mean_accuracy)\n",
    "\n",
    "    # Etapa 3 - Com o melhor hiperparâmetro, treina o modelo com todos os k folds dos dados de treino\n",
    "    print(accuracies_kvals)\n",
    "    best_k = kVals[accuracies_kvals.index(max(accuracies_kvals))]\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "    model.fit(data[train], labels[train])\n",
    "    \n",
    "    score = model.score(data[test], labels[test])\n",
    "    accuracies.append(score)\n",
    "    print(f\"\\n Best K: {best_k}, Accuracy: {score*100} \\n\")\n",
    "\n",
    "# Etapa 4 - Tira a média das k acurácias\n",
    "mean_accuracy = mean(accuracies)\n",
    "print(\"========================================\\n Mean Accuracy \\n========================================\")\n",
    "print(\"mean accuracy: %.2f%%\" % (mean_accuracy*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora treinando o modelo com todo o conjunto de dados de treino, utilizando o melhor K obtido da validação cruzada K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=31, accuracy=62.50%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, stratify=labels, test_size=0.2, random_state=42)\n",
    "\n",
    "best_k = 31\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evalute model\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"k=%d, accuracy=%.2f%%\" % (best_k, score * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree com K-Fold externo e interno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree não precisa que os dados estejam normalizados, então irei utilizar as features da forma que são retiradas do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values[:, :-1]\n",
    "labels = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362, 0.6099415204678362]\n",
      "['entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy']\n",
      "\n",
      " Best max_depth: 10, Best criterion: entropy, Accuracy: 62.5 \n",
      "\n",
      "[0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889, 0.6888888888888889]\n",
      "['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini']\n",
      "\n",
      " Best max_depth: 10, Best criterion: gini, Accuracy: 73.91304347826086 \n",
      "\n",
      "[0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
      "['entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy']\n",
      "\n",
      " Best max_depth: 10, Best criterion: entropy, Accuracy: 82.6086956521739 \n",
      "\n",
      "[0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398, 0.5818713450292398]\n",
      "['entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy']\n",
      "\n",
      " Best max_depth: 10, Best criterion: entropy, Accuracy: 86.95652173913044 \n",
      "\n",
      "[0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263, 0.6894736842105263]\n",
      "['entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy', 'entropy']\n",
      "\n",
      " Best max_depth: 10, Best criterion: entropy, Accuracy: 65.21739130434783 \n",
      "\n",
      "========================================\n",
      " Mean Accuracy \n",
      "========================================\n",
      "mean accuracy: 74.24%\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "max_depth_vals = np.arange(10, 101, 10)\n",
    "criterion_vals = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "# Etapa 1 - Separar em treino e teste\n",
    "accuracies = []\n",
    "for train, test in skf.split(data, labels):\n",
    "\n",
    "    # Etapa 2 - Para cada valor de hiperparametro\n",
    "    accuracies_max_depth_vals = []\n",
    "    best_criterion_for_x_max_depth = []\n",
    "    for max_depth in max_depth_vals:\n",
    "\n",
    "        accuracies_criterion_vals = []\n",
    "        for criterion in criterion_vals:\n",
    "        # Etapa 2 - Para cada fold\n",
    "            models_accuracies = []\n",
    "            for t_train, t_test in skf.split(data[train], labels[train]):\n",
    "\n",
    "                # Etapa 2 - Treinar um modelo e medir a acurácia\n",
    "                model = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=42)\n",
    "                model.fit(data[train[t_train]], labels[train[t_train]])\n",
    "                score = model.score(data[train[t_test]], labels[train[t_test]])\n",
    "                models_accuracies.append(score)\n",
    "\n",
    "            # Etapa 2 - Salvar a acurácia média dos k folds para cada hiperparametro\n",
    "            criterion_mean_accuracy = mean(models_accuracies)\n",
    "            accuracies_criterion_vals.append(criterion_mean_accuracy)\n",
    "\n",
    "        # Etapa 2 - Salvar o melhor hiperparametro 'criterion' para cada X max depth\n",
    "        best_criterion_for_x_max_depth.append(criterion_vals[accuracies_criterion_vals.index(max(accuracies_criterion_vals))])\n",
    "        accuracies_max_depth_vals.append(max(accuracies_criterion_vals))\n",
    "\n",
    "    print(accuracies_max_depth_vals)\n",
    "    print(best_criterion_for_x_max_depth)\n",
    "\n",
    "    # Etapa 3 - Com os melhores hiperparâmetros, treinar o modelo com todos os k folds dos dados de treino\n",
    "    best_max_depth = max_depth_vals[accuracies_max_depth_vals.index(max(accuracies_max_depth_vals))]\n",
    "    best_criterion = best_criterion_for_x_max_depth[accuracies_max_depth_vals.index(max(accuracies_max_depth_vals))]\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=best_max_depth, criterion=best_criterion, random_state=42)\n",
    "    model.fit(data[train], labels[train])\n",
    "\n",
    "    # Etapa 3 - Para cada K fold calcula a acurácia do modelo\n",
    "    y_pred = model.predict(data[test])\n",
    "    score = accuracy_score(labels[test], y_pred)\n",
    "    accuracies.append(score)\n",
    "\n",
    "    print(f\"\\n Best max_depth: {best_max_depth}, Best criterion: {best_criterion}, Accuracy: {score*100} \\n\")\n",
    "\n",
    "# Etapa 4 - Tira a média das k acurácias\n",
    "mean_accuracy = mean(accuracies)\n",
    "print(\"========================================\\n Mean Accuracy \\n========================================\")\n",
    "print(\"mean accuracy: %.2f%%\" % (mean_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " Model Final Accuracy \n",
      "========================================\n",
      "max_depth: 10, criterion: entropy, accuracy: 74.24%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "best_max_depth = 10\n",
    "best_criterion = 'entropy'\n",
    "model = DecisionTreeClassifier(max_depth=best_max_depth, criterion=best_criterion, random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"========================================\\n Model Final Accuracy \\n========================================\")\n",
    "print(\"max_depth: %d, criterion: %s, accuracy: %.2f%%\" % (best_max_depth, best_criterion, mean_accuracy*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Com base nas acurácias finais com os melhores hiperparâmetros escolhidos para cada modelo, infere-se que a Árvore de Decisão é melhor nesse caso.</p>\n",
    "<p>Entretanto, é curioso que na utilização do KNN sem o Kfold, percebe-se que o melhor K é 5 e em nenhum momento durante a utilização da validação cruzada, o K = 5 aparece com uma boa acurácia, mas os melhores valores foram K = 3, 21 e 31, que ao serem utilizados com todos os dados não criam um modelo tão preciso quanto ao K = 5. </p> \n",
    "<p>Portanto, imagina-se que a quantidade de dados (cerca de 100 samples nesse dataset) não foi suficiente para que o modelo convergisse completamente, visto que cada conjunto do K-Fold interno utilizado para decidir o melhor K, tinha um tamaho de aproximadamente 20 amostras</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
